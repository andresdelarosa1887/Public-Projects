{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic_Regression.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"m_7857TzztK4","colab_type":"code","colab":{}},"source":["# Import the necessary modules\n","from sklearn.model_selection import  train_test_split\n","from sklearn.linear_model import LogisticRegression \n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","\n","# Create training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, \n","                                                    y, \n","                                                    test_size = 0.4, \n","                                                    random_state=42)\n","\n","# Create the classifier: logreg\n","logreg= LogisticRegression()\n","\n","# Fit the classifier to the training data\n","logreg.fit(X_train, y_train)\n","\n","# Predict the labels of the test set: y_pred\n","y_pred = logreg.predict(X_test)\n","\n","# Compute and print the confusion matrix and classification report\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test, y_pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"75pUemY7zvq-","colab_type":"code","colab":{}},"source":["# Import necessary modules\n","from sklearn.metrics import roc_curve\n","\n","# Compute predicted probabilities: y_pred_prob\n","y_pred_prob = logreg.predict_proba(X_test)[:,1]\n","\n","# Generate ROC curve values: fpr, tpr, thresholds\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n","# Plot ROC curve\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.plot(fpr, tpr)\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_KBJ9IO3CkI","colab_type":"code","colab":{}},"source":["# Import necessary modules\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import cross_val_score\n","\n","# Compute predicted probabilities: y_pred_prob\n","y_pred_prob = logreg.predict_log_proba(X_test)[:,1]\n","\n","# Compute and print AUC score\n","print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n","\n","# Compute cross-validated AUC scores: cv_auc\n","cv_auc = cross_val_score(logreg, X, y, cv=5, scoring='roc_auc')\n","\n","# Print list of AUC scores\n","print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))\n"],"execution_count":0,"outputs":[]}]}