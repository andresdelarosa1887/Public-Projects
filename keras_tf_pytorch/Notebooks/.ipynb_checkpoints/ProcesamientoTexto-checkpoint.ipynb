{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de paragraph vector\n",
    "En este ejemplo se entrenará un modelo utilizando *[paragraph vector](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)*, también conocido como *Doc2Vec*. En concreto usaremos la implementación proporcionada por [gensim](https://radimrehurek.com/gensim/models/doc2vec.html).\n",
    "Los pasos necesarios para obtener el vector de *features* para un texto es:\n",
    "1. Cargar los textos a procesar\n",
    "2. Entrenar el modelo de Doc2Vec\n",
    "3. Obtener la codificación para los textos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 1: Carga de los textos a procesar\n",
    "Cargaremos el csv de datos que se encuentra en la ruta '../datasets/Recursos_turisticos.csv', en el cual se almacena en cada linea los datos de un recursos turístico. Para este ejemplo usaremso el campo 'strDescripcion'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de documentos: 601\n",
      "\n",
      "\n",
      "Ejemplo de un documento:\n",
      "\n",
      "Enclavado en una situación privilegiada con fantásticas vistas a la sierra, y a menos de 2 Km. del centro de la ciudad de Ronda y 45 Km. de la Costa del Sol, es un lugar ideal para disfrutar de la oferta cultural y gastronómica además del patrimonio histórico-artístico de la ciudad, pudiendo combinarla con actividades en su entorno natural como la Sierra de las Nieves (reserva de la biosfera). Su decoración de estilo moderno y actual ofrece un ambiente selecto y acogedor. En nuestro restaurante podrán degustar los platos de nuestro cocinero Antonio Castro Aguilar además de una exquisita carta de vinos..\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "recursos = pd.read_csv('../datasets/Recursos_turisticos.csv', sep='|')\n",
    "recursos.head(5)\n",
    "\n",
    "documentos = recursos['strDescripcion']\n",
    "print \"Numero de documentos:\", len(documentos)\n",
    "print \"\\n\\nEjemplo de un documento:\\n\\n\", documentos[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargado los datos del csv, añadimos estos a la variable `tagged_data` en la que se almacenará el texto *tokenizado*, es decir partido por palabras, y una etiqueta, en este caso el numero del documentos. \n",
    "Para el *tokenizado* se usa la función `word_tokenize` proporcionada por la biblioteca `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.decode('utf-8') .lower()), tags=[str(i)]) for i, _d in enumerate(documentos)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 2: Entrenamiento del modelo de Doc2Vec\n",
    "Los modelos de Doc2Vec requieren para su entrenamiento el fijar los valores para una serie de hiperparámetros, que son:\n",
    "* **Longitud del vector**: longitud del vector de *features* que se generará por el modelo\n",
    "* **Ventana**: tamaño de la ventana de palabras que usará el modelo\n",
    "* **Frecuencia mínima**: frecuencia mínima de apariciones que debe tener un término para que sea tomado en consideración\n",
    "* ***Learning rate***: valor inicial para el *learning rate* en el proceso de entrenamiento\n",
    "* ***Mínimo learning rate***: valor mínimo de *learning rate* que se usará en el proceso de entrenamiento\n",
    "* ***Epoch***: número de iteraciones máximas del proceso de entrenamiento\n",
    "\n",
    "En un proceso de entrenamiento para producción es necesario realizar un proceso de busquedas de los valores a usar, recomendandose el uso de [busqueda aleatoria](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf). \n",
    "\n",
    "En este ejemplo para evitar la demora de la búsqueda de hiperparámetros se asignarán unos valores por defecto, que son:\n",
    "* **Longitud del vector**: 5\n",
    "* **Ventana**: 10\n",
    "* **Frecuencia mínima**: 5\n",
    "* ***Learning rate***: 0.025\n",
    "* ***Mínimo learning rate***: 0.025\n",
    "* ***Epoch***: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41015326976776123, -0.6406916379928589, -1.5952590703964233, 3.8950421810150146, 0.6677010655403137]\n",
      "[1.6461111307144165, 1.719222903251648, -0.04054301977157593, 1.8220890760421753, 0.950815737247467]\n",
      "[-2.7238411903381348, 2.4118847846984863, -0.9959932565689087, 3.8765854835510254, 1.7178045511245728]\n",
      "[-2.682331085205078, 1.3908506631851196, 2.109365463256836, 4.925195693969727, 3.41788387298584]\n",
      "[-0.16584119200706482, 0.7495830655097961, 3.441272497177124, 2.577284336090088, 1.3693571090698242]\n",
      "[0.24096928536891937, 4.7898149490356445, 0.1739889532327652, 2.8192317485809326, 0.18219101428985596]\n",
      "[2.6826171875, 1.635993242263794, -0.18182489275932312, -0.61750727891922, 0.7514306902885437]\n",
      "[-1.5459681749343872, 4.541253566741943, -0.2771131992340088, 1.0310827493667603, 1.0837702751159668]\n",
      "[0.3874787390232086, -1.9611867666244507, 2.082097291946411, 1.6078522205352783, 1.858471393585205]\n",
      "[1.1283841133117676, 2.493962526321411, -1.6594595909118652, 4.6127166748046875, -0.3505018651485443]\n",
      "[-0.12155698984861374, 4.295114517211914, 0.07559143751859665, -1.3369663953781128, 3.499760627746582]\n",
      "[1.5341523885726929, -0.6190601587295532, 0.18394409120082855, 2.4227514266967773, 2.1797165870666504]\n",
      "[3.65313458442688, 3.1022391319274902, -1.4818601608276367, -0.7039921879768372, 0.5515885353088379]\n",
      "[1.2729791402816772, 5.752038478851318, 3.0723190307617188, 0.8432267904281616, -0.3415951430797577]\n",
      "[4.653979778289795, 0.7441534399986267, -0.5058646202087402, 1.6674808263778687, -0.7276495695114136]\n",
      "[-1.5099025964736938, 0.4470572769641876, -2.1515328884124756, 5.809207916259766, 2.058237075805664]\n",
      "[-0.5755164623260498, 2.1968705654144287, -1.597425103187561, 2.9782891273498535, 0.7374230027198792]\n",
      "[0.21087220311164856, 1.6456571817398071, -2.036940097808838, 5.272002220153809, 0.9577428102493286]\n",
      "[2.792470693588257, 3.796501398086548, 0.4743310511112213, -1.8551985025405884, 0.8965011835098267]\n",
      "[-0.17555633187294006, 0.3903663754463196, 0.9476545453071594, 1.4394508600234985, -0.9772893190383911]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "#Configuración\n",
    "#-------------\n",
    "__longitud_vector = 5\n",
    "__ventana = 10\n",
    "__frecuencia_minima = 5\n",
    "__learning_rate = 0.025\n",
    "__min_learning_rate = 0.025\n",
    "__epoch = 100\n",
    "#---------------------\n",
    "\n",
    "                \n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.decode('utf-8') .lower()), tags=[str(i)]) for i, _d in enumerate(documentos)]\n",
    "model = Doc2Vec(vector_size=__longitud_vector, window=__ventana, min_count=__frecuencia_minima, workers=11,alpha=__learning_rate, min_alpha=__min_learning_rate, epochs=__epoch)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, epochs=model.epochs, total_examples=model.corpus_count)\n",
    "\n",
    "#Recorrido de todos los documentos con los que se ha entrenado\n",
    "for i in range(20):\n",
    "    print model.docvecs[i].tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 3: Obtener la codificación para los textos\n",
    "Existen dos caminos alternativos para la obtención de las *features* de los documentos, dependiendo si son documentos que se han usado para el entrenamiento y se encuentrán en el modelo o si son documentos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener *features* para los textos de entrenamiento\n",
    "En el siguiente ejemplo se obtienen las *features* de los primeros veinte documentos usados en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41015326976776123, -0.6406916379928589, -1.5952590703964233, 3.8950421810150146, 0.6677010655403137]\n",
      "[1.6461111307144165, 1.719222903251648, -0.04054301977157593, 1.8220890760421753, 0.950815737247467]\n",
      "[-2.7238411903381348, 2.4118847846984863, -0.9959932565689087, 3.8765854835510254, 1.7178045511245728]\n",
      "[-2.682331085205078, 1.3908506631851196, 2.109365463256836, 4.925195693969727, 3.41788387298584]\n",
      "[-0.16584119200706482, 0.7495830655097961, 3.441272497177124, 2.577284336090088, 1.3693571090698242]\n",
      "[0.24096928536891937, 4.7898149490356445, 0.1739889532327652, 2.8192317485809326, 0.18219101428985596]\n",
      "[2.6826171875, 1.635993242263794, -0.18182489275932312, -0.61750727891922, 0.7514306902885437]\n",
      "[-1.5459681749343872, 4.541253566741943, -0.2771131992340088, 1.0310827493667603, 1.0837702751159668]\n",
      "[0.3874787390232086, -1.9611867666244507, 2.082097291946411, 1.6078522205352783, 1.858471393585205]\n",
      "[1.1283841133117676, 2.493962526321411, -1.6594595909118652, 4.6127166748046875, -0.3505018651485443]\n",
      "[-0.12155698984861374, 4.295114517211914, 0.07559143751859665, -1.3369663953781128, 3.499760627746582]\n",
      "[1.5341523885726929, -0.6190601587295532, 0.18394409120082855, 2.4227514266967773, 2.1797165870666504]\n",
      "[3.65313458442688, 3.1022391319274902, -1.4818601608276367, -0.7039921879768372, 0.5515885353088379]\n",
      "[1.2729791402816772, 5.752038478851318, 3.0723190307617188, 0.8432267904281616, -0.3415951430797577]\n",
      "[4.653979778289795, 0.7441534399986267, -0.5058646202087402, 1.6674808263778687, -0.7276495695114136]\n",
      "[-1.5099025964736938, 0.4470572769641876, -2.1515328884124756, 5.809207916259766, 2.058237075805664]\n",
      "[-0.5755164623260498, 2.1968705654144287, -1.597425103187561, 2.9782891273498535, 0.7374230027198792]\n",
      "[0.21087220311164856, 1.6456571817398071, -2.036940097808838, 5.272002220153809, 0.9577428102493286]\n",
      "[2.792470693588257, 3.796501398086548, 0.4743310511112213, -1.8551985025405884, 0.8965011835098267]\n",
      "[-0.17555633187294006, 0.3903663754463196, 0.9476545453071594, 1.4394508600234985, -0.9772893190383911]\n"
     ]
    }
   ],
   "source": [
    "#Recorrido de los 20 primeros documentos con los que se ha entrenado\n",
    "for i in range(20):\n",
    "    print model.docvecs[i].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener features para nuevos textos\n",
    "Gracias al método `infer_vector` del modelo se permite obtener las *features* de un nuevo texto, el cual se pasa al método como una lista de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24811527 0.14234225 0.06730658 0.3178042  0.35057995]\n"
     ]
    }
   ],
   "source": [
    "featuresNuevoTexto = model.infer_vector([\"Esto\", \"es\", \"un\", \"texto\", \"desconocido\", \"para\", \"el\", \"modelo\"])\n",
    "print featuresNuevoTexto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
