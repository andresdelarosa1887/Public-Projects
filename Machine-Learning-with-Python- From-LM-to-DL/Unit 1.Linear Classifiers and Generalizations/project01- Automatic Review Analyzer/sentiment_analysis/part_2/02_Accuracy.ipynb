{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "\n",
    "We have supplied you with an accuracy function:\n",
    "\n",
    "def accuracy(preds, targets):\n",
    "    \"\"\"\n",
    "    Given length-N vectors containing predicted and target labels,\n",
    "    returns the percentage and number of correct predictions.\n",
    "    \"\"\"\n",
    "    return (preds == targets).mean()\n",
    "The accuracy function takes a numpy array of predicted labels and a numpy array of actual labels and returns the prediction accuracy. You should use this function along with the functions that you have implemented thus far in order to implement classifier_accuracy.\n",
    "\n",
    "The classifier_accuracy function should take 6 arguments:\n",
    "\n",
    "a classifier function that, itself, takes arguments (feature_matrix, labels, **kwargs)\n",
    "\n",
    "the training feature matrix\n",
    "\n",
    "the validation feature matrix\n",
    "\n",
    "the training labels\n",
    "\n",
    "the valiation labels\n",
    "\n",
    "a **kwargs argument to be passed to the classifier function\n",
    "\n",
    "This function should train the given classifier using the training data and then compute compute the classification accuracy on both the train and validation data. The return values should be a tuple where the first value is the training accuracy and the second value is the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "##Classifier- Im using pegasos\n",
    "from string import punctuation, digits\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def get_order(n_samples):\n",
    "    try:\n",
    "        with open(str(n_samples) + '.txt') as fp:\n",
    "            line = fp.readline()\n",
    "            return list(map(int, line.split(',')))\n",
    "    except FileNotFoundError:\n",
    "        random.seed(1)\n",
    "        indices = list(range(n_samples))\n",
    "        random.shuffle(indices)\n",
    "        return indices\n",
    "    \n",
    "def pegasos_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        L,\n",
    "        eta,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    if label*(feature_vector@current_theta + current_theta_0) <= 1:\n",
    "        current_theta =  (1 - eta*L)*current_theta + eta*label*feature_vector\n",
    "        current_theta_0 = current_theta_0 + eta*label\n",
    "    else:\n",
    "        current_theta =  (1 - eta*L)*current_theta\n",
    "    return (current_theta, current_theta_0)\n",
    "\n",
    "def classifier(feature_matrix, labels, T, L):\n",
    "    pegasos_theta = np.zeros(len(feature_matrix[0])) \n",
    "    pegasos_theta_0 = 0\n",
    "    update_counter = 0\n",
    "    # updating perceptrons\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            update_counter += 1\n",
    "            eta = 1/(np.sqrt(update_counter))\n",
    "            pegasos_theta, pegasos_theta_0 = pegasos_single_step_update(feature_matrix[i],\n",
    "                                                                        labels[i],\n",
    "                                                                        L,\n",
    "                                                                        eta,\n",
    "                                                                        pegasos_theta,\n",
    "                                                                        pegasos_theta_0)\n",
    "    return (pegasos_theta, pegasos_theta_0)\n",
    "\n",
    "##Classification Function##\n",
    "def classify(feature_matrix, theta, theta_0):\n",
    "    result= []\n",
    "    for i, x in enumerate(feature_matrix): \n",
    "        if (np.dot(feature_matrix[i], theta) + theta_0) >0: \n",
    "            classification= 1\n",
    "        else:\n",
    "            classification= -1 \n",
    "        result.append(classification)\n",
    "    return(np.array(result))\n",
    "\n",
    "def accuracy(preds, targets):\n",
    "    \"\"\"\n",
    "    Given length-N vectors containing predicted and target labels,\n",
    "    returns the percentage and number of correct predictions.\n",
    "    \"\"\"\n",
    "    return (preds == targets).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_accuracy(\n",
    "        classifier,\n",
    "        train_feature_matrix,\n",
    "        val_feature_matrix,\n",
    "        train_labels,\n",
    "        val_labels,\n",
    "        T,L):\n",
    "    train_theta, train_theta_0 = classifier(train_feature_matrix, train_labels, T, L)\n",
    "    train_predictions= classify(train_feature_matrix, train_theta, train_theta_0)\n",
    "    trained_validation  = classify(val_feature_matrix, train_theta, train_theta_0)\n",
    "    train_accuracy = accuracy(train_predictions, train_labels)\n",
    "    val_accuracy = accuracy(trained_validation, val_labels)\n",
    "    return(train_accuracy, val_accuracy)\n",
    "    \n",
    "    \"\"\"\n",
    "    Trains a linear classifier and computes accuracy.\n",
    "    The classifier is trained on the train data. The classifier's\n",
    "    accuracy on the train and validation data is then returned.\n",
    "\n",
    "    Args:\n",
    "        classifier - A classifier function that takes arguments\n",
    "            (feature matrix, labels, **kwargs) and returns (theta, theta_0)\n",
    "        train_feature_matrix - A numpy matrix describing the training\n",
    "            data. Each row represents a single data point.\n",
    "        val_feature_matrix - A numpy matrix describing the training\n",
    "            data. Each row represents a single data point.\n",
    "        train_labels - A numpy array where the kth element of the array\n",
    "            is the correct classification of the kth row of the training\n",
    "            feature matrix.\n",
    "        val_labels - A numpy array where the kth element of the array\n",
    "            is the correct classification of the kth row of the validation\n",
    "            feature matrix.\n",
    "        **kwargs - Additional named arguments to pass to the classifier\n",
    "            (e.g. T or L)\n",
    "\n",
    "    Returns: A tuple in which the first element is the (scalar) accuracy of the\n",
    "    trained classifier on the training data and the second element is the\n",
    "    accuracy of the trained classifier on the validation data.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Example\n",
    "train_feature_matrix = np.array([[1, 0], [1, -1], [2, 3]])\n",
    "val_feature_matrix = np.array([[1, 1], [2, -1]])\n",
    "train_labels = np.array([1, -1, 1])\n",
    "val_labels = np.array([-1, 1])\n",
    "exp_res = 1, 0\n",
    "T=1\n",
    "L=0.2\n",
    "\n",
    "classifier_accuracy(classifier, train_feature_matrix, val_feature_matrix, train_labels, val_labels, T, L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
