{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Hinge Loss (Empirical Risk) \n",
    "\n",
    "The empirical risk Rn is defined as\n",
    "Rn(θ)=1nn∑t=1Loss(y(t)−θ⋅x(t))\t \n",
    "\n",
    "where (x(t),y(t)) is the tth training exampl\n",
    "e (and there are n in total), and Loss is some loss function, such as hinge loss.\n",
    "Recall from a previous lecture that the definition of hinge loss:\n",
    "Lossh(z)={0if z≥11−z, otherwise.\n",
    "\n",
    "In this problem, we calculate the empirical risk with hinge loss when given specific θ and {(x(t),y(t))}t=1,...,n. Assume we have 4 training examples (i.e. n=4), where x(t)∈R3 and y(t) is a scalar. The training examples {(x(t),y(t))}t=1,2,3,4 are given as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_risk(feature_matrix, labels, theta):\n",
    "    total_loss = []\n",
    "    total_loss2 = []\n",
    "    for i, x  in enumerate(feature_matrix):\n",
    "        ##The loss before applying the Hinge loss function\n",
    "        loss = labels[i] - (np.dot(feature_matrix[i], theta))\n",
    "        total_loss.append(loss)\n",
    "        ##Aplying the Hinge Loss function\n",
    "        if (labels[i] - (np.dot(feature_matrix[i], theta))) >= 1:\n",
    "            loss2=0 \n",
    "        else:\n",
    "            loss2 = 1- (labels[i] - (np.dot(feature_matrix[i], theta)))\n",
    "        total_loss2.append(loss2)\n",
    "        result= (sum(total_loss2)/len(feature_matrix))\n",
    "    return total_loss, total_loss2, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, -0.2999999999999998, 0.30000000000000004, -1.0],\n",
       " [1.0, 1.2999999999999998, 0.7, 2.0],\n",
       " 1.25)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "feature_matrix= np.array([[1,0,1],\n",
    "                          [1,1,1],\n",
    "                          [1,1,-1],\n",
    "                          [-1,1,1]])\n",
    "labels= np.array([2,\n",
    "                  2.7,\n",
    "                  -0.7,\n",
    "                  2])\n",
    "\n",
    "theta= np.array([0, 1,2])\n",
    "\n",
    "empirical_risk(feature_matrix, labels, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Squared Error Loss\n",
    "1 point possible (graded)\n",
    "Now, we will calculate the empirical risk with the squared error loss. Remember that the squared error loss is given by  \n",
    "Loss(z)= Z squared/ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_risk(feature_matrix, labels, theta):\n",
    "    total_loss = []\n",
    "    total_loss2 = []\n",
    "    for i, x  in enumerate(feature_matrix):\n",
    "        ##The loss before applying the Hinge loss function\n",
    "        loss = np.square(labels[i] - (np.dot(feature_matrix[i], theta)))/2\n",
    "        total_loss.append(loss)\n",
    "        ##Aplying the Squared Error Function\n",
    "    result= (sum(total_loss)/len(feature_matrix))\n",
    "    return  total_loss, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 0.04499999999999995, 0.04500000000000001, 0.5], 0.1475)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "feature_matrix= np.array([[1,0,1],\n",
    "                          [1,1,1],\n",
    "                          [1,1,-1],\n",
    "                          [-1,1,1]])\n",
    "labels= np.array([2,\n",
    "                  2.7,\n",
    "                  -0.7,\n",
    "                  2])\n",
    "\n",
    "theta= np.array([0, 1,2])\n",
    "\n",
    "empirical_risk(feature_matrix, labels, theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
